* Universidad Sergio Arboleda
* Big Data
* Parcial 3掳 corte
* Domingo 12 de marzo de 2023
## Ejecuci贸n de la funci贸n lambda para la descarga del archivo .html
Se describe el proceso realizado para hacer web scraping a la p谩gina de Mitula. Por un lado, se configura un evento a las 9 am de cada lunes, con el fin de que se realice un trigger hacia la funci贸n lambda y se ejecute la funci贸n f, escrita en lenguaje Python. Esta funci贸n tiene un desencadenador hacia un bucket s3 que permite guardar la p谩gina en una carpeta llamada landing-casas-xxx. Del mismo modo, para realizar el web scraping se debe leer el archivo obteniendo el contenido en formato html almacenado en el primer bucket.

### Expresi贸n Cron - Agendar evento 
En el archivo zappa_settings.json se especifica el nombre del archivo Python y la funci贸n. Asimismo, se establece que todos los lunes a las 9 am se active la funci贸n lambda. Inicialmente establec铆 la expresi贸n de la siguiente manera: cron(0 9 ? '*' MON '*'). En el momento de validar el historial de registros en CloudWatch se evidenciaba que no se ejecutaba la funci贸n. Despu茅s de varias pruebas e investigando en la documentaci贸n de Amazon, encontr茅 que el servicio lambda viene de manera predeterminada con el uso de la zona horaria UTC, com煤nmente utilizada en varias partes del mundo. Esta era la raz贸n de por qu茅 no se ejecutaba a la hora especificada en la funci贸n cron. Despu茅s de validar que existen 5 horas de diferencia, modifiqu茅 el evento para que se ejecutara a las 13 horas, es decir, las 10 horas en la zona horaria de Bogot谩 (UTC-5).

Como ejemplo de prueba, para este caso queria que mi funci贸n lambda se ejecutar谩 a las 11:18PM hora local, para esto deberia utilizar la expresion cron(18 4 ? '*' MON '*'). Entendido esto, despues configure mi expressi贸n en el archivo zappa_settings para que se desencadenara una acci贸n todos los lunes a las 9 am.

![Texto alternativo](https://i.postimg.cc/bJfzCZYG/Captura-de-pantalla-2023-03-12-231529.png)

A continuaci贸n, se muestra una captura de pantalla de la subida de la p谩gina al primer bucket y la subida de un archivo CSV en el segundo bucket.

![Texto alternativo](https://i.postimg.cc/g25chMfH/Captura-de-pantalla-2023-03-12-232012.png)

![Texto alternativo](https://i.postimg.cc/K84vRXsY/Captura-de-pantalla-2023-03-12-231937.png)

Se realizaron varias pruebas para que finalmente se obtuviera la siguiente estructura del archivo CSV:

![Texto alternativo](https://i.postimg.cc/yNZ1ymK4/Captura-de-pantalla-2023-03-12-233355.png)

### Configuraci贸n de las funciones lambda - Zappa

En el archivo JSON de nombre zappa_settings se realiza la declaraci贸n del nombre de la funci贸n lambda y el archivo. En mi caso, utilic茅 dos ambientes de trabajo en donde cada uno tuviera la declaraci贸n de una funci贸n con la zona de despliegue, bucket de almacenamiento y el rol de usuario para obtener los permisos necesarios.
Los siguientes comandos fueron utilizados para desplegar o actualizar los servicios necesarios para la puesta en marcha de la funci贸n lambda 
```
zappa init
```

```
zappa deploy dev
```
```
zappa update dev
```

```
zappa schedule dev
```
### Web scraping - Extracci贸n de datos 

Primero se valida cu谩l fue el 煤ltimo archivo HTML subido al primer bucket. Esta b煤squeda se realiza encontrando la diferencia entre la fecha actual y la fecha de subida para archivo, mediante el atributo Lastmodified del diccionario contents. Posteriormente, se analiza y se encuentra los datos de cada casa a trav茅s de BeautifulSoup que permite encontrar todas las etiquetas de la clase listing listing-card. Por otra parte, se observa que existe una generalidad en la p谩gina, ya que en cada etiqueta de clase listing-lising card se tiene como atributos, la cantidad de ba帽os, habitaciones y precio. Para cada casa, en algunas ocasiones no se especifica la cantidad de ba帽os o habitaciones, es por esto que primero se realiza una validaci贸n en donde si no se especifica la cantidad se ingresa un valor nulo a la lista.
Se program贸 de manera que cada atributo de la casa representara una lista que se encuentra contenida en un diccionario, que despu茅s a trav茅s de la librer铆a de Pandas vamos a poder obtener nuestro archivo .csv.

```
flake8 .
```

### Pruebas unitarias 
1. Se simula la descarga de una p谩gina web utilizando la biblioteca urllib.request y se valida el contenido HTML descargado.

3. Se hace una prueba para validar si el nombre de dominio se encuentra asociado a una direcci贸n ip que permite saber en que lugar del mundo se encuentra ubicado el servidor.

3. Se realiza la petici贸n de tipo GET a la pagina de mitula y se recibe un codigo que se encuentra en el encabezado del mensaje que permite validar si existieron problemas de comunicaci贸n desde la parte del cliente o del servidor.

4. Se obtiene un archivo html a partir de la url de la pagina de Mitula y despues se aloja en un bucket s3. Para conocer si esta operaci贸n fue exitosa, se analiza la meta data de la respuesta. La solicitud es satisfactoria y sin erorres cuando se recibe un 200 como respuesta. 

```
def validate_code(url):
    return urllib.request.urlopen(url).getcode()

```
![Texto alternativo](https://i.postimg.cc/0NBSbdCT/Captura-de-pantalla-2023-03-12-234133.png)


## Revisi贸n de codigo limpio
La libreria flake8 permitia examinar los archivos especilamnete de lenguaje python con el fin de advertir errores de sintaxis,redundancia de codigo, el nivel de complejidad de las funciones,variables o impoertaciones no utilizadas durante el desarrollo del cdogio. Se crea un archvio de configuraci贸n perosnaliazdo en donde se decide que tipo de reglas aplicar.
```
flake8 --config=.flake8
```
